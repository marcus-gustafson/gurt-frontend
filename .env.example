# Optional: set your local OpenAI-compatible base URL
# If not set, the app probes http://localhost:8080/v1 then http://localhost:1234/v1
OPENAI_BASE_URL=

# Optional for some servers (ignored by llama.cpp / LM Studio)
OPENAI_API_KEY=

# Default model id; can be changed in Settings
MODEL_ID=oss-20b

# Default system prompt (also changeable in Settings)
DEFAULT_SYSTEM_PROMPT=You are Gurt, a private, local-first assistant. Be fast, practical, and concise by default. Explain more only when asked. Never send data to external services.

# Expose only *defaults* to the client; keys are never exposed
NEXT_PUBLIC_MODEL_ID=oss-20b
NEXT_PUBLIC_DEFAULT_SYSTEM_PROMPT=You are Gurt, a private, local-first assistant. Be fast, practical, and concise by default. Explain more only when asked. Never send data to external services.
